{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "179f55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0047213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to draw text to the screen \n",
    "def draw_text(img, text, font=cv2.FONT_HERSHEY_PLAIN, pos=(0, 0),\n",
    "          font_scale=3, font_thickness=2,\n",
    "          text_color=(0, 255, 0), text_color_bg=(255, 255, 255)):\n",
    "    \n",
    "    x, y = pos\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    text_w, text_h = text_size\n",
    "    cv2.rectangle(img, pos, (x + text_w, y + text_h), text_color_bg, -1)\n",
    "    cv2.putText(img, text, (x, y + text_h + font_scale - 1), font, font_scale, text_color, font_thickness)\n",
    "\n",
    "    return text_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ab01f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define labels and the model to use\n",
    "labels = ['paper', 'rock', 'scissor']\n",
    "model = tf.keras.models.load_model('model_my_data_781,923_0.926')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "428f4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the video\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    # Read form the camara\n",
    "    ret, frame_original = cap.read()\n",
    "    \n",
    "    # Set greyscale and threshold values to use as the model input\n",
    "    frame = cv2.cvtColor(frame_original, cv2.COLOR_BGR2GRAY)\n",
    "    ret, frame = cv2.threshold(frame,180,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Resize for the model\n",
    "    frame = cv2.resize(frame, (128,128), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Resize to see better on camera \n",
    "    frame_resized = cv2.resize(frame, (512,512))#, interpolation = cv2.INTER_AREA)\n",
    "    frame_display = frame_resized # DEBUG temporary variable \n",
    "    \n",
    "    # Predict the value and draw the text on the frame \n",
    "    prediction = model.predict(np.resize(frame,(1,128,128,1))/255) \n",
    "    draw_text(frame_display, labels[np.argmax(prediction)], pos=(20,20))\n",
    "    \n",
    "    # Show the frame\n",
    "    cv2.imshow('OpenCv', frame_display)\n",
    "    \n",
    "    draw_text(frame_display, labels[np.argmax(prediction)], pos=(20,20))\n",
    "    \n",
    "    \n",
    "    # Set the Q key to stop the video\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de36e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images for training \n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "labels = ['paper' , 'rock', 'scissor']\n",
    "k = [1,1,1]\n",
    "while(True):\n",
    "    # Read form the camara\n",
    "    ret, frame_original = cap.read()\n",
    "    \n",
    "    # Set greyscale and threshold values to use as the model input\n",
    "    frame = cv2.cvtColor(frame_original, cv2.COLOR_BGR2GRAY)\n",
    "    ret, frame = cv2.threshold(frame,180,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Resize for the model\n",
    "    frame = cv2.resize(frame, (128,128), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Resize to see better on camera \n",
    "    #frame_resized = cv2.resize(frame, (512,512))#, interpolation = cv2.INTER_AREA)\n",
    "    frame_display = frame # DEBUG temporary variable \n",
    "    \n",
    "    #draw_text(frame_display, labels[np.argmax(prediction)], pos=(20,20))\n",
    "    aux = cv2.waitKey(1);\n",
    "    if aux & 0xFF == ord('p'):\n",
    "        cv2.imwrite(\"my_data/paper/paper%d.jpg\" % k[0], frame)\n",
    "        draw_text(frame_display, 'paper', pos=(20,20))\n",
    "        k[0] += 1\n",
    "    if aux & 0xFF == ord('r'):\n",
    "        cv2.imwrite(\"my_data/rock/rock%d.jpg\" % k[1], frame)\n",
    "        draw_text(frame_display, 'rock', pos=(20,20))\n",
    "        k[1] += 1\n",
    "    if aux & 0xFF == ord('s'):\n",
    "        cv2.imwrite(\"my_data/scissor/scissor%d.jpg\" % k[2], frame)\n",
    "        draw_text(frame_display, 'scissor', pos=(20,20))\n",
    "        k[2] += 1\n",
    "    \n",
    "    # Show the frame\n",
    "    cv2.imshow('OpenCv', frame_display)\n",
    "    \n",
    "    # Set the Q key to stop the video\n",
    "    if aux & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43113b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time per prediction [ms]: 55.929\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# See how long it takes to predict with the selected model\n",
    "\n",
    "\n",
    "N = 100\n",
    "test_array = np.random.randint(2,size=(1,128,128,1,N))\n",
    "results = np.zeros((N))\n",
    "\n",
    "start = time.time()\n",
    "for i in range(N):\n",
    "    prediction = model.predict(test_array[:,:,:,:,i]) \n",
    "end = time.time() \n",
    "\n",
    "print('Time per prediction [ms]: ' + str(np.round(1000*(end-start)/N,3)))\n",
    "\n",
    "for i in range(N):\n",
    "    prediction = model.predict(test_array[:,:,:,:,i]) \n",
    "    results[i] = np.argmax(prediction)\n",
    "\n",
    "plt.hist(results,[0,1,2,3],align='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f67de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "258ba099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97cfd2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07171150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
